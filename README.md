# Toxic-Comment-Classifier-Project
 Given dataset is a group of sentences, used as a comment by a user in an online 
platform. The task is to build a model which could make prediction to classify the 
comments into following  categories.

 • TOXIC
 
 • SEVERE TOXIC
 
 • OBSCENE
 
 • THREAT
 
 • INSULT OR IDENTITY HATE

 Utilizing one-vs-rest classification on diverse classification algorithms like Naive Bayes, Random Forest, LSTM, etc to attain the highest accuracy to categorize comments by toxicity level across multiple categories. 
